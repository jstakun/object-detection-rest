{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection\n",
    "\n",
    "In notebook [1_explore.ipynb](1_explore.ipynb) we saw how to use a pre-trained object detection model to identify objects in a static image. In this notebook, we consider which parts of the code we used are crucial in making a prediction, and remove the code which was merely used to explore the data. \n",
    "\n",
    "You might have noticed that this folder we are working in contains afew files we haven't talked about. This 'project' has been set up for us by our Super Star Application Developer, and contains everything we need to easily go from experiment to application. \n",
    "\n",
    "The process we will be using to create our application is called source-to-image, or s2i. Don't worry if you've never heard of it! We will step you through what you need to do! For now, take a look at the way in which the project is organised:\n",
    "\n",
    "### Project Organization\n",
    "```\n",
    ".\n",
    "├── README.md\n",
    "├── LICENSE\n",
    "├── requirements.txt        <- Used to install packages for s2i application\n",
    "├── 1_explore.ipynb         <- Notebook for data and use case exploration\n",
    "├── 2_predict.ipynb         <- Notebook for creating a predict function\n",
    "├── 3_run_flask.ipynb       <- Notebook for running flask locally to test\n",
    "├── 4_test_flask.ipynb      <- Notebook for testing flask requests\n",
    "├── .gitignore              <- standard python gitignore\n",
    "├── .s2i                    <- hidden folder for advanced s2i configuration\n",
    "│   └── environment         <- s2i environment settings\n",
    "├── gunicorn_config.py      <- configuration for gunicorn when run in OpenShift\n",
    "├── prediction.py           <- the predict function called from Flask\n",
    "└── wsgi.py                 <- basic Flask application\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "In the previous notebook, all of our libraries were already installed for us because we selected the 'tensorflow' notebook image from the Jupyterhub spawner. However, when we run the model as part of an application we need to ensure we are packaging the model with the correct requirements. Take a look at the `requirements.txt` file to see which libraries we need for our application.\n",
    "\n",
    "\n",
    "We can install these libraries into our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "id": "KUu4vOt5zI9d"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Predict Function\n",
    "\n",
    "Extract the prediction logic into a standalone python file, `prediction.py` in a `predict` function.  Also, make sure `requirements.txt` is updated with any additional packages you've used and need for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import base64\n",
    "\n",
    "model_dir = 'models/openimages_v4_ssd_mobilenet_v2_1'\n",
    "saved_model = tf.saved_model.load(model_dir)\n",
    "detector = saved_model.signatures['default']\n",
    "\n",
    "\n",
    "def predict(body):\n",
    "    base64img = body.get('image')\n",
    "    img_bytes = base64.decodebytes(base64img.encode())\n",
    "    detections = detect(img_bytes)\n",
    "    cleaned = clean_detections(detections)\n",
    "    \n",
    "    return { 'detections': cleaned }\n",
    "\n",
    "\n",
    "def detect(img):    \n",
    "    image = tf.image.decode_jpeg(img, channels=3)\n",
    "    converted_img  = tf.image.convert_image_dtype(image, tf.float32)[tf.newaxis, ...]\n",
    "    result = detector(converted_img)\n",
    "    num_detections = len(result[\"detection_scores\"])\n",
    "    \n",
    "    output_dict = {key:value.numpy().tolist() for key, value in result.items()}\n",
    "    output_dict['num_detections'] = num_detections\n",
    "    \n",
    "    return output_dict\n",
    "\n",
    "\n",
    "def clean_detections(detections):\n",
    "    cleaned = []\n",
    "    # max_boxes = 10\n",
    "    # num_detections = min(detections['num_detections'], max_boxes)\n",
    "    num_detections = detections['num_detections']\n",
    "\n",
    "    for i in range(0, num_detections):\n",
    "        label = detections['detection_class_entities'][i].decode('utf-8')\n",
    "        score = detections['detection_scores'][i]\n",
    "        if score > 0.3:\n",
    "            d = {\n",
    "                'box': {\n",
    "                    'yMin': detections['detection_boxes'][i][0],\n",
    "                    'xMin': detections['detection_boxes'][i][1],\n",
    "                    'yMax': detections['detection_boxes'][i][2],\n",
    "                    'xMax': detections['detection_boxes'][i][3]\n",
    "                },\n",
    "                'class': label,\n",
    "                'label': label,\n",
    "                'score': score,\n",
    "            }\n",
    "            cleaned.append(d)\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def clean_detections(detections):\n",
    "    cleaned = []\n",
    "    max_boxes = 10\n",
    "    num_detections = min(detections['num_detections'], max_boxes)\n",
    "\n",
    "    for i in range(0, num_detections):\n",
    "        d = {\n",
    "            'box': {\n",
    "                'yMin': detections['detection_boxes'][i][0],\n",
    "                'xMin': detections['detection_boxes'][i][1],\n",
    "                'yMax': detections['detection_boxes'][i][2],\n",
    "                'xMax': detections['detection_boxes'][i][3]\n",
    "            },\n",
    "            'class': detections['detection_class_entities'][i].decode('utf-8'),\n",
    "            'label': detections['detection_class_entities'][i].decode('utf-8'),\n",
    "            'score': detections['detection_scores'][i],\n",
    "        }\n",
    "        cleaned.append(d)\n",
    "\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('sample-requests/twodogs.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "result = predict(data)\n",
    "print(result['detections'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, you can see that we only need a few lines of code to be able to make a prediction - much of the code in the first notebook was for exploration only. \n",
    "\n",
    "\n",
    "We've put the code from this notebook into the `prediction.py` file, as that is where the source-to-image builder will look for our prediction function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Object detection",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
